rm(list=ls())
############### DATOS ###############
y=  c(25.5, 31.2, 25.9, 38.4,  18.4, 26.7, 26.4, 25.9, 32,   25.2,  39.7,  35.7, 26.5 )
x1= c( 1.74, 6.32, 6.2, 10.52,  1.19, 1.22, 4.10, 6.32, 4.08, 4.15, 10.15,  1.72, 1.70)
x2= c( 5.30, 5.42, 8.41, 4.63, 11.60, 5.85, 6.62, 8.72, 4.42, 7.60,  4.83,  3.12, 5.3 )
x3= c(10.8,  9.4,  7.2,  8.5,   9.4,  9.9,  8,    9.1,  8.7,  9.2,   9.4,   7.6,  8.2 )

##### 0) Analizar gráficos de disperción y pruebas de correlación

base<-data.frame(y,x1,x2,x3)
#View(base)
plot(base)

# Se puede ver en las gráficas que:
# la relación que tiene y con x1 es positiva
# la relación de y con x2 es negativa
# y entre y y x3 no hay una relación ya que están muy dispersos los datos

cor(base, use="everything", method = "pearson")

# Como se puede ver en la correlación, x1 y x2 tiene mucha relación con y sólo
# que la relación de x1 es positiva y la de x2 es negativa.
# También se puede observar que x3 tiene muy poca relación con y.

##### 1) Plantear la ecuación estimada original, es decir con todas las variables
modelo<- lm(y~x1+x2+x3)
summary(modelo)

# La ecuación de y quedaría así: y=39.1767+1.0166x1-1.8608x2-0.3461x3


##### 2) Analizar la anova, r cuadrada, estadístico F (mediante p.h.)

anova(modelo) 
# como se puede ver x1 y x2 son significativos
# R cuadrada =0.9119 -> el modelo replicará acertadamente el 88.25% 
# de los datos 
# F=31.04 Y p-value= 0.00004465 -> cumple con los criterios de un buen ajuste


##### 3) Comparen modelos con backward y analicen el modelo
##### que genere la función step
##### con analizar me refiero a... los incisos 0,1,2 (en dado caso que la función
##### step genere el mismo modelo que el modelo completo hagan caso omiso a esto)

step(modelo, direction="backward")
#Aquí podemos ver que el método step analizó 2 modelos:
#1) y ~ x1+x2+x3 con un AIC=22.15
#2) y ~ x1+x2 con un AIC=20.6
###Por lo cual el mejor modelo es el que considera y~x1+x2
modelo2<- lm(y~x1+x2, data=base)
base$ajus <- fitted (modelo2)
base$resi <- residuals(modelo2)
base$rstud<- rstudent(modelo2)

##### 4) Realizar la prueba de 3 supuestos a este modelo (kolmogorov-smirnov, 
##### breusch-pagan y durvin watson) analicen los resultados de estas pruebas

##### NORMALIDAD
install.packages("lmtest")
require (lmtest)
ks.test(base$rstud, "pnorm")
##### histograma
hist(base$rstud, xlab = "residuales", main = "Hist residuales")
##### El p-value para el contraste de normalidad es mayor que 0.05 (p= 0.5483),
##### el histograma se parece a una distribución normal sesgada a la izquierda
##### por lo que si hay problemas de normalidad.

##### homogeneidad de varianzas
bptest(modelo2, studentize = FALSE, data = base)
##### p=0.394 > 0.005 entonces la varianza es constante a lo largo de la muestra.

dwtest(modelo, alternative = "two.sided", data = base)
##### Aceptamos la hipótesis nula de que no existe correlación entre los residuos
##### con un p-valor superior a 0.05 p-value= 0.4128
